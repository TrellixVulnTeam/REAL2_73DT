[Wed, 03 Nov 2021 01:22:12] INFO [main: run_main_batch.py, 60] pid:22882, epoch:50
[Wed, 03 Nov 2021 01:22:12] INFO [main: run_main_batch.py, 61] args:Namespace(Fold=1, add_analogy_embedding=True, add_copynet=True, add_memory_module=True, add_num_equ_ids=True, add_tokens_a_padding=True, always_truncate_tail=True, amp=False, attention_probs_dropout_prob=0.1, batch_size=20, beam_size=1, bert_model='bert-base-chinese', config_path=None, copynet_name='copynet2', dataset='math23k_test1k', do_eval=False, do_l2r_training=False, do_lower_case=False, do_train=True, easy_to_hard=True, eval_batch_size=64, ffn_type=0, finetune_decay=False, forbid_duplicate_ngrams=False, forbid_ignore_word='.', fp16=False, fp32_embedding=False, from_scratch=False, gradient_accumulation_steps=1, has_sentence_oracle=False, hidden_dropout_prob=0.1, ids_questions_path='../preprocess/raw_sim_dict/raw_math23k_test1k_data_dict.pkl', is_debug=False, is_delete_early_model=False, is_equ_norm=True, is_single_char=False, is_train=False, label_smoothing=0.1, learning_rate=2e-05, length_penalty=0, local_rank=-1, log_dir='../comment/math23k/model_log', loss_scale=0, mask_prob=0.15, mask_prob_eos=0, mask_source_words=False, mask_whole_word=True, max_analogy_len=512, max_len_a=192, max_len_b=64, max_position_embeddings=512, max_pred=64, max_seq_length=256, max_tgt_length=64, memory_train_file='../preprocess/sim_result/sim_question_by_w2v_train_math23k_test1000_equNorm_top5.pkl', memory_valid_file='../preprocess/sim_result/sim_question_by_w2v_valid_math23k_test1k_equNorm_top10.pkl', min_len=None, mode='s2s', model_recover_path='../comment/math23k/REAL2_math23k_test1k_topn5_top5_bert/model.epoch.bin', need_score_traces=True, new_pos_ids=False, new_segment_ids=False, ngram_size=3, no_cuda=False, not_predict_token=None, num_equ_size=3, num_qkv=0, num_train_epochs=50, num_workers=0, optim_recover_path=None, output_dir='../comment/math23k/REAL2_math23k_test1k_topn5_top5_bert', pos_shift=True, pred_wo_memory_copy=False, relax_projection=False, repeat='', retrieve_model_name='bert', retrieve_result_path='', retrieve_topn=5, s2s_add_segment=False, s2s_share_segment=False, s2s_special_token=False, save_every_epoch=False, seed=42, seg_emb=False, skipgram_prb=0.0, skipgram_size=1, split='test', start_lr_decay_epoch=25, subset=0, tokenized_input=False, topk=5, train_batch_size=1, train_question_sim_ids_path='../preprocess/raw_sim_dict/math23k_test1k_train_sim_id_top10.pkl', trunc_seg='a', used_bertAdam=False, used_lr_decay=True, valid_question_sim_ids_path='../preprocess/raw_sim_dict/math23k_test1k_valid_sim_id_top10.pkl', warmup_proportion=0.1, weight_decay=0.01)
[Wed, 03 Nov 2021 01:22:13] INFO [get_from_cache: file_utils.py, 197] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt not found in cache, downloading to /tmp/tmp_3y5kd44
[Wed, 03 Nov 2021 01:22:15] INFO [get_from_cache: file_utils.py, 210] copying /tmp/tmp_3y5kd44 to cache at ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 01:22:15] INFO [get_from_cache: file_utils.py, 214] creating metadata file for ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 01:22:15] INFO [get_from_cache: file_utils.py, 220] removing temp file /tmp/tmp_3y5kd44
[Wed, 03 Nov 2021 01:22:15] INFO [from_pretrained: tokenization.py, 197] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 01:22:15] INFO [main_generation: decoder_seq2seq_mwp.py, 168] ../comment/math23k/REAL2_math23k_test1k_topn5_top5_bert/model.50.bin
[Wed, 03 Nov 2021 01:22:18] INFO [get_from_cache: file_utils.py, 197] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to /tmp/tmp7utc5wan
[Wed, 03 Nov 2021 01:24:19] INFO [get_from_cache: file_utils.py, 210] copying /tmp/tmp7utc5wan to cache at ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 01:24:23] INFO [get_from_cache: file_utils.py, 214] creating metadata file for ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 01:24:23] INFO [get_from_cache: file_utils.py, 220] removing temp file /tmp/tmp7utc5wan
[Wed, 03 Nov 2021 01:24:23] INFO [from_pretrained: modeling_mwp.py, 774] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 01:24:23] INFO [from_pretrained: modeling_mwp.py, 782] extracting archive file ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmpnt_9hh3k
[Wed, 03 Nov 2021 01:24:42] INFO [from_pretrained: modeling_mwp.py, 1077] Weights from pretrained model not used in BertForSeq2SeqDecoder: ['cls2.predictions.bias', 'cls2.predictions.transform.dense.weight', 'cls2.predictions.transform.dense.bias', 'cls2.predictions.transform.LayerNorm.weight', 'cls2.predictions.transform.LayerNorm.bias', 'cls2.predictions.decoder.weight', 'cls2.seq_relationship.weight', 'cls2.seq_relationship.bias', 'crit_mask_lm_smoothed.one_hot']
[Wed, 03 Nov 2021 01:24:47] INFO [main_generation: decoder_seq2seq_mwp.py, 258] easy_nums:175, medium_nums:515, upper_nums:194, hard_nums:116
[Wed, 03 Nov 2021 01:27:40] INFO [eval_5fold: eval.py, 107] acc_right: 184, question_total: 200, uneval: 0, correct score: 0.9200
[Wed, 03 Nov 2021 01:30:34] INFO [eval_5fold: eval.py, 107] acc_right: 364, question_total: 400, uneval: 0, correct score: 0.9100
[Wed, 03 Nov 2021 01:33:27] INFO [eval_5fold: eval.py, 107] acc_right: 549, question_total: 600, uneval: 0, correct score: 0.9150
[Wed, 03 Nov 2021 01:36:22] INFO [eval_5fold: eval.py, 107] acc_right: 710, question_total: 800, uneval: 2, correct score: 0.8875
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 850, question_total: 1000, uneval: 5, correct score: 0.8500
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 850, question_total: 1000, uneval: 5, correct score: 0.8500
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 162, question_total: 175, uneval: 0, correct score: 0.9257
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 467, question_total: 515, uneval: 2, correct score: 0.9068
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 148, question_total: 194, uneval: 0, correct score: 0.7629
[Wed, 03 Nov 2021 01:39:16] INFO [eval_5fold: eval.py, 107] acc_right: 73, question_total: 116, uneval: 3, correct score: 0.6293
[Wed, 03 Nov 2021 02:24:48] INFO [main: run_main_batch.py, 64] pid:296, epoch:50
[Wed, 03 Nov 2021 02:24:48] INFO [main: run_main_batch.py, 65] args:Namespace(Fold=1, add_analogy_embedding=True, add_copynet=True, add_memory_module=True, add_num_equ_ids=True, add_tokens_a_padding=True, always_truncate_tail=True, amp=False, attention_probs_dropout_prob=0.1, batch_size=20, beam_size=1, bert_model='bert-base-chinese', config_path=None, copynet_name='copynet2', dataset='math23k_test1k', do_eval=False, do_l2r_training=False, do_lower_case=False, do_train=True, easy_to_hard=True, eval_batch_size=64, ffn_type=0, finetune_decay=False, forbid_duplicate_ngrams=False, forbid_ignore_word='.', fp16=False, fp32_embedding=False, from_scratch=False, gradient_accumulation_steps=1, has_sentence_oracle=False, hidden_dropout_prob=0.1, ids_questions_path='./preprocess/raw_sim_dict/raw_math23k_test1k_data_dict.pkl', is_debug=False, is_delete_early_model=False, is_equ_norm=True, is_single_char=False, is_train=False, label_smoothing=0.1, learning_rate=2e-05, length_penalty=0, local_rank=-1, log_dir='./comment/math23k/model_log', loss_scale=0, mask_prob=0.15, mask_prob_eos=0, mask_source_words=False, mask_whole_word=True, max_analogy_len=512, max_len_a=192, max_len_b=64, max_position_embeddings=512, max_pred=64, max_seq_length=256, max_tgt_length=64, memory_train_file='./preprocess/sim_result/sim_question_by_w2v_train_math23k_test1000_equNorm_top10.pkl', memory_valid_file='./preprocess/sim_result/sim_question_by_w2v_valid_math23k_test1k_equNorm_top10.pkl', min_len=None, mode='s2s', model_recover_path='./comment/math23k/REAL2_math23k_test1k_topn5_top5_bert/model.epoch.bin', need_score_traces=True, new_pos_ids=False, new_segment_ids=False, ngram_size=3, no_cuda=False, not_predict_token=None, num_equ_size=3, num_qkv=0, num_train_epochs=50, num_workers=0, optim_recover_path=None, output_dir='./comment/math23k/REAL2_math23k_test1k_topn5_top5_bert', pos_shift=True, pred_wo_memory_copy=False, relax_projection=False, repeat='', retrieve_model_name='bert', retrieve_result_path='', retrieve_topn=5, s2s_add_segment=False, s2s_share_segment=False, s2s_special_token=False, save_every_epoch=False, seed=42, seg_emb=False, skipgram_prb=0.0, skipgram_size=1, split='test', start_lr_decay_epoch=25, subset=0, tokenized_input=False, topk=5, train_batch_size=1, train_question_sim_ids_path='./preprocess/raw_sim_dict/math23k_test1k_train_sim_id_top10.pkl', trunc_seg='a', used_bertAdam=False, used_lr_decay=True, valid_question_sim_ids_path='./preprocess/raw_sim_dict/math23k_test1k_valid_sim_id_top10.pkl', warmup_proportion=0.1, weight_decay=0.01)
[Wed, 03 Nov 2021 02:24:49] INFO [get_from_cache: file_utils.py, 197] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt not found in cache, downloading to /tmp/tmp1yskgx9p
[Wed, 03 Nov 2021 02:24:51] INFO [get_from_cache: file_utils.py, 210] copying /tmp/tmp1yskgx9p to cache at ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 02:24:51] INFO [get_from_cache: file_utils.py, 214] creating metadata file for ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 02:24:51] INFO [get_from_cache: file_utils.py, 220] removing temp file /tmp/tmp1yskgx9p
[Wed, 03 Nov 2021 02:24:51] INFO [from_pretrained: tokenization.py, 197] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at ..comment/tmp_folder/bert-cased-pretrained-cache/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00
[Wed, 03 Nov 2021 02:24:52] INFO [main_generation: decoder_seq2seq_mwp.py, 168] ./comment/math23k/REAL2_math23k_test1k_topn5_top5_bert/model.50.bin
[Wed, 03 Nov 2021 02:24:59] INFO [get_from_cache: file_utils.py, 197] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to /tmp/tmpugs1n4f0
[Wed, 03 Nov 2021 02:29:11] INFO [get_from_cache: file_utils.py, 210] copying /tmp/tmpugs1n4f0 to cache at ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 02:29:15] INFO [get_from_cache: file_utils.py, 214] creating metadata file for ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 02:29:15] INFO [get_from_cache: file_utils.py, 220] removing temp file /tmp/tmpugs1n4f0
[Wed, 03 Nov 2021 02:29:15] INFO [from_pretrained: modeling_mwp.py, 774] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Wed, 03 Nov 2021 02:29:15] INFO [from_pretrained: modeling_mwp.py, 782] extracting archive file ..comment/tmp_folder/bert-cased-pretrained-cache/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmptg2bdhjb
[Wed, 03 Nov 2021 02:29:31] INFO [from_pretrained: modeling_mwp.py, 1077] Weights from pretrained model not used in BertForSeq2SeqDecoder: ['cls2.predictions.bias', 'cls2.predictions.transform.dense.weight', 'cls2.predictions.transform.dense.bias', 'cls2.predictions.transform.LayerNorm.weight', 'cls2.predictions.transform.LayerNorm.bias', 'cls2.predictions.decoder.weight', 'cls2.seq_relationship.weight', 'cls2.seq_relationship.bias', 'crit_mask_lm_smoothed.one_hot']
[Wed, 03 Nov 2021 02:29:39] INFO [main_generation: decoder_seq2seq_mwp.py, 258] easy_nums:175, medium_nums:515, upper_nums:194, hard_nums:116
[Wed, 03 Nov 2021 02:32:22] INFO [eval_5fold: eval.py, 107] acc_right: 184, question_total: 200, uneval: 0, correct score: 0.9200
[Wed, 03 Nov 2021 02:35:07] INFO [eval_5fold: eval.py, 107] acc_right: 364, question_total: 400, uneval: 0, correct score: 0.9100
[Wed, 03 Nov 2021 02:37:51] INFO [eval_5fold: eval.py, 107] acc_right: 549, question_total: 600, uneval: 0, correct score: 0.9150
[Wed, 03 Nov 2021 02:40:35] INFO [eval_5fold: eval.py, 107] acc_right: 710, question_total: 800, uneval: 2, correct score: 0.8875
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 850, question_total: 1000, uneval: 5, correct score: 0.8500
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 850, question_total: 1000, uneval: 5, correct score: 0.8500
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 162, question_total: 175, uneval: 0, correct score: 0.9257
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 467, question_total: 515, uneval: 2, correct score: 0.9068
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 148, question_total: 194, uneval: 0, correct score: 0.7629
[Wed, 03 Nov 2021 02:43:19] INFO [eval_5fold: eval.py, 107] acc_right: 73, question_total: 116, uneval: 3, correct score: 0.6293
